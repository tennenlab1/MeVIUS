{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09e341cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "406fd264",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pre-process\n",
    "#import packages\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "#rename file names\n",
    "def my_removesuffix(s, suffix):\n",
    "    return s[:-len(suffix)] if s.endswith(suffix) else s\n",
    "def my_removeprefix(s1, prefix):\n",
    "    if s1.startswith(prefix):\n",
    "        return s1[len(prefix):]\n",
    "    else:\n",
    "        return s1\n",
    "    \n",
    "#reformat values (m/z, RT, MSintensity) for further analysis (data from the MVs-treated samples) \n",
    "for p in glob.iglob('IMPORTED CSV FILE'):\n",
    "    basename = os.path.splitext(os.path.basename(p))[0]\n",
    "    basename_without_p = basename.my_removeprefix('REDUNDANT LABEL TO BE REMOVED').my_removesuffix('REDUNDANT LABEL TO BE REMOVED')\n",
    "    df = pd.read_csv(p)\n",
    "\n",
    "    df.columns = ['mz', 'RT', 'intensity', 'no']\n",
    "    from decimal import Decimal, ROUND_HALF_UP\n",
    "    s_mz = df['mz']\n",
    "    s_mz2= s_mz.map(lambda x: float(Decimal(str(x)).\n",
    "                            quantize(Decimal('0.1'), rounding=ROUND_HALF_UP)))\n",
    "    s_mz3 = s_mz2.astype(float)\n",
    "    s_RT = df['RT']\n",
    "    s_RT2= s_RT.map(lambda x: float(Decimal(str(x)).\n",
    "                            quantize(Decimal('0.01'), rounding=ROUND_HALF_UP)))\n",
    "    s_RT3 = s_RT2.astype(float)\n",
    "    s_area = df['intensity']\n",
    "    s_area2= s_area.map(lambda x: float(Decimal(str(x)).\n",
    "                            quantize(Decimal('0'), rounding=ROUND_HALF_UP)))\n",
    "    s_area3 = s_area2.astype(float)\n",
    "    plus_df = pd.DataFrame({'mz': s_mz3, 'RT': s_RT3, 'intensity': s_area3})\n",
    "    plus_df.to_csv(basename_without_p+\"p.csv\", index=None)\n",
    "    \n",
    "new_Folder = 'REFORMATED FOLDER''\n",
    "for ed in glob.iglob('REFORMATED CSV FILES'): \n",
    "    shutil.move(ed,'REFORMATED FOLDER')\n",
    "#\"p.csv\" indicates common label for files contain metabolites from the MVs-treated bacteria\n",
    "#\"basename_without_p+p.csv\" files are defined REFORMATED CSV FILES\n",
    "    \n",
    "#reformat values (m/z, RT, MSintensity) for further analysis (data from non-treated samples) \n",
    "for n in glob.iglob('IMPORTED CSV FILE'):\n",
    "    basename = os.path.splitext(os.path.basename(n))[0]\n",
    "    basename_without_n = basename.my_removeprefix('REDUNDANT LABEL TO BE REMOVED').my_removesuffix('REDUNDANT LABEL TO BE REMOVED')\n",
    "    df = pd.read_csv(n)\n",
    "\n",
    "    df.columns = ['mz', 'RT', 'intensity', 'no']\n",
    "    from decimal import Decimal, ROUND_HALF_UP\n",
    "    s_mz = df['mz']\n",
    "    s_mz2= s_mz.map(lambda x: float(Decimal(str(x)).\n",
    "                            quantize(Decimal('0.1'), rounding=ROUND_HALF_UP)))\n",
    "    s_mz3 = s_mz2.astype(float)\n",
    "    s_RT = df['RT']\n",
    "    s_RT2= s_RT.map(lambda x: float(Decimal(str(x)).\n",
    "                            quantize(Decimal('0.01'), rounding=ROUND_HALF_UP)))\n",
    "    s_RT3 = s_RT2.astype(float)\n",
    "    s_area = df['intensity']\n",
    "    s_area2= s_area.map(lambda x: float(Decimal(str(x)).\n",
    "                            quantize(Decimal('0'), rounding=ROUND_HALF_UP)))\n",
    "    s_area3 = s_area2.astype(float)\n",
    "    minus_df = pd.DataFrame({'mz': s_mz3, 'RT': s_RT3, 'intensity': s_area3})\n",
    "    minus_df.to_csv(basename_without_n+\"n.csv\", index=None)\n",
    "    \n",
    "new_Folder = 'REFORMATED FOLDER''\n",
    "for ed in glob.iglob('REFORMATED CSV FILES'): \n",
    "    shutil.move(ed,'REFORMATED FOLDER')\n",
    "#\"n.csv\" indicates common label for files contain metabolites from non-treated bacteria\n",
    "#\"basename_without_n+n.csv\" files are defined REFORMATED CSV FILES\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51c8dfcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pre-process\n",
    "#replicate reformated csv files (data from the MVs-treated samples)\n",
    "for cut in glob.iglob('REFORMATED FILES in REFORMATED FOLDER'): \n",
    "    basename_p = os.path.splitext(os.path.basename(cut))[0]\n",
    "    df1 = pd.read_csv(cut)\n",
    "    \n",
    "#correct ionization efficiency between each LC-MS batch by MS intensity of reserpine\n",
    "    df1 = df1[df1['intensity'] >= 25000] #fold change of reserpine MS intensity between two LC-MS batches\n",
    "    df1 = df1.reset_index()\n",
    "    df1 = df1.drop('index', axis=1)\n",
    "    df1.to_csv(basename_p+\".csv\", index=None)\n",
    "new_Folder = 'CORRECTED FOLDER''\n",
    "for ed in glob.iglob('CORRECTED CSV FILES'): \n",
    "    shutil.move(ed,'CORRECTED FOLDER')\n",
    "    \n",
    "#replicate reformated csv files (data from non-treated samples)\n",
    "for cut in glob.iglob('REFORMATED CVS FILES in REFORMATED FOLDER'): \n",
    "    basename_n = os.path.splitext(os.path.basename(cut))[0]\n",
    "    df2 = pd.read_csv(cut)\n",
    "    \n",
    "#correct ionization efficiency between each LC-MS batch by MS intensity of reserpine\n",
    "    df2 = df2[df2['intensity'] >= 25000] #fold change of reserpine MSintensity between two LC-MS batches\n",
    "    df2 = df2.reset_index()\n",
    "    df2 = df2.drop('index', axis=1)\n",
    "    df2.to_csv(basename_n+\".csv\", index=None)\n",
    "new_Folder = 'CORRECTED FOLDER''\n",
    "for ed in glob.iglob('CORRECTED CSV FILES'): \n",
    "    shutil.move(ed,'CORRECTED FOLDER')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b9ffc17",
   "metadata": {},
   "outputs": [],
   "source": [
    "#step1\n",
    "#compare masses in between the MVs-treated samples and non-treated samples\n",
    "for p in glob.iglob('CORRECTED CSV FILES in CORRECTED FOLDER'):\n",
    "    basename_p = os.path.splitext(os.path.basename(p))[0]\n",
    "    basename_without_p = basename_p.rstrip('p')\n",
    "    plus_df = pd.read_csv(p)\n",
    "    for n in glob.iglob('CORRECTED CSV FILES in CORRECTED FOLDER'):\n",
    "        basename_n = os.path.splitext(os.path.basename(n))[0]\n",
    "        basename_without_n = basename_n.rstrip('n')\n",
    "        minus_df = pd.read_csv(n)\n",
    "        \n",
    "        \n",
    "        if basename_without_p == basename_without_n:\n",
    "            list=[]\n",
    "            list2=[]\n",
    "            for plus_i in plus_df.itertuples():\n",
    "                for minus_i in minus_df.itertuples():\n",
    "                    if minus_i[1]-0.2<=plus_i[1]<=minus_i[1]+0.2 and minus_i[2]-0.19<=plus_i[2]<=minus_i[2]+0.19:\n",
    "                        list.append(plus_i)\n",
    "                        list2.append(minus_i)\n",
    "           # 0.2 and 0.19 are used for acceptable deviation of m/z             \n",
    "            overlap_with_duplicates_df = pd.DataFrame(list)\n",
    "            overlap_with_duplicates_df2 = pd.DataFrame(list2)\n",
    "\n",
    "            overlap_df = overlap_with_duplicates_df.drop_duplicates(subset=['mz', 'RT'])\n",
    "            overlap_df = overlap_df.drop('Index', axis=1)\n",
    "            overlap_df2 = overlap_with_duplicates_df2.drop_duplicates(subset=['mz', 'RT'])\n",
    "            overlap_df2 = overlap_df2.drop('Index', axis=1)\n",
    "\n",
    "            overlap_df.to_csv(basename_without_p+\"_overlapplus.csv\")\n",
    "            overlap_df2.to_csv(basename_without_n+\"_overlapminus.csv\")\n",
    "\n",
    "            \n",
    "            #pick up masses which are present only in the MVs-treated samples\n",
    "            df3 = pd.merge(plus_df,overlap_df, on=['mz', 'RT'], how='outer', indicator=True)\n",
    "            plus_only_df = df3[df3['_merge'] == 'left_only'].iloc[:,:3]\n",
    "            plus_only_df = plus_only_df.rename(columns={'intensity_x': 'intensity'})\n",
    "            plus_only_df.to_csv(basename_without_p+\"_plusonly.csv\")\n",
    "            #\"basename_without_p+_plusonly.csv\" files are defined UNIQUE MASS FILES\n",
    "            \n",
    "            #pick up masses which are presence in both of the MVs-treated and non-treated samples\n",
    "            df4 = overlap_with_duplicates_df\n",
    "            df4 = df4.drop('Index', axis=1)\n",
    "            df5 = overlap_with_duplicates_df2\n",
    "            df5 = df5.drop('Index', axis=1)\n",
    "\n",
    "            df6 = pd.concat([df4, df5], axis=1, ignore_index=True)\n",
    "            df6[\"ratio\"] = np.nan\n",
    "            def warizan(x):\n",
    "                return x.iloc[2] / x.iloc[5]\n",
    "            df6[\"ratio\"] = df6.apply(warizan, axis=1)\n",
    "            df6=df6.drop(columns=[3,4,5])\n",
    "            df6.rename(columns={df6.columns[0]: 'mz'}, inplace=True)\n",
    "            df6.rename(columns={df6.columns[1]: 'RT'}, inplace=True)\n",
    "            df6.rename(columns={df6.columns[2]: 'intensity'}, inplace=True)\n",
    "            df6.to_csv(basename_without_p+\"_overlap.csv\") \n",
    "            #\"basename_without_p+_overlap.csv\" files are defined OVERLAPPED MASS FILES  \n",
    "            \n",
    "new_Folder = 'UNIQUE MASS FOLDER''\n",
    "for ed in glob.iglob('UNIQUE MASS FILES'): \n",
    "    shutil.move(ed,'UNIQUE MASS FOLDER')\n",
    "new_Folder = 'OVERLAPPED MASS FOLDER''\n",
    "for ed in glob.iglob('OVERLAPPED MASS FILES'): \n",
    "    shutil.move(ed,'OVERLAPPED MASS FOLDER')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16582d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "#step2\n",
    "#pick up common masses between UNIQUE MASS FILEs and background masses\n",
    "\n",
    "for p in glob.iglob('UNIQUE MASS FILES in UNIQUE MASS FOLDER'):\n",
    "    basename = os.path.splitext(os.path.basename(p))[0]\n",
    "    df_a = pd.read_csv(p)\n",
    "    df_a = df_a.drop('Unnamed: 0', axis=1)\n",
    "    df_b = pd.read_csv(\"BACKGROUND MASSS FILE\")\n",
    "    #masses from Burkholderia multivotrans and media ingredient are listed in the BACKGROUND MASSS FILE\n",
    "    df_b = df_b.drop('Unnamed: 0', axis=1)\n",
    "    list=[]\n",
    "    list2=[]\n",
    "    for df_a_i in df_a.itertuples():\n",
    "        for df_b_i in df_b.itertuples():\n",
    "            if df_b_i[1]-0.2<=df_a_i[1]<=df_b_i[1]+0.2 and df_b_i[2]-1.19<=df_a_i[2]<=df_b_i[2]+1.19:\n",
    "                list.append(df_a_i)\n",
    "                list2.append(df_b_i)\n",
    "\n",
    "    overlap_with_duplicates_df_a = pd.DataFrame(list)\n",
    "    overlap_with_duplicates_df_b = pd.DataFrame(list2)\n",
    "\n",
    "    overlap_df = overlap_with_duplicates_df_a.drop_duplicates(subset=['mz', 'RT'])\n",
    "    overlap_df.to_csv(basename+\"_sameback.csv\")\n",
    "    #\"basename+_sameback.csv\" files are defined COMMON COMPOUNDS FILES\n",
    "\n",
    "new_Folder = 'COMMON COMPOUNDS FOLDER''\n",
    "for ed in glob.iglob('COMMON COMPOUNDS FILES'): \n",
    "    shutil.move(ed,'COMMON COMPOUNDS FOLDER')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f562bac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#step2\n",
    "#exclude background masses picked up in the above from UNIQUE MASS FILEs\n",
    "\n",
    "for p in glob.iglob('UNIQUE MASS FILES in UNIQUE MASS FOLDER'):\n",
    "    basename_u = os.path.splitext(os.path.basename(p))[0]\n",
    "    basename_without_u = basename_u.rstrip('_plusonly')\n",
    "    df_a = pd.read_csv(p)\n",
    "    df_a = df_a.drop('Unnamed: 0', axis=1)\n",
    "    for n in glob.iglob('COMMON COMPOUNDS FILES in COMMON COMPOUNDS FOLDER'):\n",
    "        basename_c = os.path.splitext(os.path.basename(n))[0]\n",
    "        basename_without_c = basename_c.rstrip('_plusonly_sameback')\n",
    "        df_b = pd.read_csv(n)\n",
    "        df_b = df_b.drop('Unnamed: 0', axis=1)\n",
    "        df_b = df_b.drop('Index', axis=1)\n",
    "        \n",
    "        if basename_without_u == basename_without_c:\n",
    "            df_db = pd.merge(df_a, df_b, on=['RT', 'mz'], how='outer', indicator=True)\n",
    "            plus_only_db_df = df_db[df_db['_merge'] == 'left_only'].iloc[:,:5]\n",
    "            plus_only_db_df = plus_only_db_df.rename(columns={'intensity_x': 'intensity'})\n",
    "            plus_only_db_df.to_csv(basename_u+\"_delback.csv\")\n",
    "            #\"basename_u+_delback.csv\" files are defined UNIQUE METABOLITE FILES\n",
    "            \n",
    "new_Folder = 'UNIQUE METABOLITE FOLDER''\n",
    "for ed in glob.iglob('UNIQUE METABOLITE FILES'): \n",
    "    shutil.move(ed,'UNIQUE METABOLITE FOLDER')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea9e1ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#step3\n",
    "#pick up the MVs-induced masses from OVERLAPPED MASS FILEs\n",
    " \n",
    "for ov in glob.iglob('OVERLAPPED MASS FILES　in OVERLAPPED MASS FOLDER'):\n",
    "    basename = os.path.splitext(os.path.basename(ov))[0]\n",
    "    basename_without = basename.rstrip('_overlap')\n",
    "    df_t = pd.read_csv(ov)\n",
    "    df_t = df_t.drop('Unnamed: 0', axis=1)    \n",
    "    df_t = df_t[df_t['ratio'] >= 3] # pick up >3-fold induced metabolites\n",
    "    df_t = df_t.reset_index()\n",
    "    df_t = df_t.drop('index', axis=1)\n",
    "    df_t.to_csv(basename_without+\"_ratio.csv\", index=None)\n",
    "    #\"basename_without+_ratio.csv\" files are defined >3 OVERLAPPED MASS FILES\n",
    "\n",
    "new_Folder = '>3 OVERLAPPED MASS FOLDER''\n",
    "for ed in glob.iglob('>3 OVERLAPPED MASS FILES'): \n",
    "shutil.move(ed,'>3 OVERLAPPED MASS FOLDER')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c95fabf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#step4\n",
    "#pick up common masses between >3 OVERLAPPED MASS FILEs and background masses\n",
    "   \n",
    "for p in glob.iglob('>3 OVERLAPPED MASS FILES in >3 OVERLAPPED MASS FOLDER'):\n",
    "    basename = os.path.splitext(os.path.basename(p))[0]\n",
    "    df_a = pd.read_csv(p)\n",
    "    df_b = pd.read_csv(\"BACKGROUND COMPOUNDS CSV FILE\")\n",
    "    #masses from Burkholderia multivotrans and media ingredient are listed in the BACKGROUND MASSS FILE\n",
    "    df_b = df_b.drop('Unnamed: 0', axis=1)\n",
    "    list=[]\n",
    "    list2=[]\n",
    "    for df_a_i in df_a.itertuples():\n",
    "        for df_b_i in df_b.itertuples():\n",
    "            if df_b_i[1]-0.2<=df_a_i[1]<=df_b_i[1]+0.2 and df_b_i[2]-1.19<=df_a_i[2]<=df_b_i[2]+1.19:\n",
    "                list.append(df_a_i)\n",
    "                list2.append(df_b_i)\n",
    "\n",
    "    overlap_with_duplicates_df_a = pd.DataFrame(list)\n",
    "    overlap_with_duplicates_df_b = pd.DataFrame(list2)\n",
    "\n",
    "    overlap_df = overlap_with_duplicates_df_a.drop_duplicates(subset=['mz', 'RT'])\n",
    "    overlap_df.to_csv(basename+\"_sameback.csv\")\n",
    "    #\"basename+_sameback.csv\" files are defined COMMON OVERLAPPED COMPOUNDS FILES\n",
    "    \n",
    "new_Folder = 'COMMON OVERLAPPED COMPOUNDS FILES FOLDER''\n",
    "for ed in glob.iglob('COMMON OVERLAPPED COMPOUNDS FILES'): \n",
    "shutil.move(ed,'COMMON OVERLAPPED COMPOUNDS FOLDER')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c76ff1b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#step4\n",
    "#exclude background masses from >3 OVERLAPPED MASS FILEs\n",
    "\n",
    "for p in glob.iglob('>3 OVERLAPPED MASS CSV FILES in >3 OVERLAPPED MASS FOLDER'):\n",
    "    basename_o = os.path.splitext(os.path.basename(p))[0]\n",
    "    basename_without_o = basename_o.rstrip('_ratio')\n",
    "    df_a = pd.read_csv(p)\n",
    "    for n in glob.iglob('COMMON OVERLAPPED COMPOUNDS FILES in COMMON OVERLAPPED COMPOUNDS FOLDER'):\n",
    "        basename_c = os.path.splitext(os.path.basename(n))[0]\n",
    "        basename_without_c = basename_c.rstrip('_ratio_sameback')\n",
    "        df_b = pd.read_csv(n)\n",
    "        df_b = df_b.drop('Unnamed: 0', axis=1)\n",
    "        df_b = df_b.drop('Index', axis=1)\n",
    "        \n",
    "        if basename_without_o == basename_without_c:\n",
    "            df_db = pd.merge(df_a, df_b, on=['RT', 'mz'], how='outer', indicator=True)\n",
    "            plus_only_db_df = df_db[df_db['_merge'] == 'left_only'].iloc[:,:4]\n",
    "            plus_only_db_df = plus_only_db_df.rename(columns={'intensity_x': 'intensity'})\n",
    "            plus_only_db_df.to_csv(basename_o+\"_delback.csv\")\n",
    "        #\"basename_o+_delback.csv\" files are defined INDUCED METABOLITE FILES\n",
    "        \n",
    "new_Folder = 'INDUCED METABOLITE FOLDER''\n",
    "for ed in glob.iglob('INDUCED METABOLITE FILES'): \n",
    "shutil.move(ed,'INDUCED METABOLITE FOLDER')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
